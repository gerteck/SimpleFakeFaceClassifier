# Simple Fake Face Classifier
The purpose of this repository is to train a simple machine learning model to classify
whether an image is real or is a fake face generated by Artificial Intelligence. (AI)

## Installing and Importing Python Libraries

```commandline
pip install scikit-plot
pip install gdown
```
```python
import os
import PIL.Image #for image preprocessing
import numpy as np #for multi-dimensional arrays processing
import sklearn.linear_model #contain multiple machine learning functions
#More info: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model

import matplotlib.pyplot as plt

# %matplotlib inline ( inline magic command for jupyter notebook if  operating on google colab.)

import scikitplot as skplt #for advance visualisation of model performance
from tqdm import tqdm
from IPython.display import Image, display
import gdown

```

Next, download the dataset and unzip the data set

```python
#Downloading our compressed dataset
gdown.download("https://drive.google.com/file/d/1TSH3rgWLQF4kopKE61neK0oemdOzHNEv/view?usp=drive_link", output="data.zip", quiet=False, fuzzy=True)
# Unzip the files on allocated colab directory
unzip -o -q data.zip -d data
```

## Examples of Images in the Dataset:
Install Pillow or PIL in Pycharm or IDE
```commandline
$ pip install pillow
```
```python
from PIL import Image
print("Flickr Real Image")
with Image.open('data/train/ffhq/00032.png') as img:
    img.show()

print("StyleGan2 Fake Image")
with Image.open('data/train/stylegan2/000005.png') as img:
    img.show()
```



## Dataset Statistics:
ffhq (positive/real images) 500 images for training and 500 images for validation

stylegan2 (negative/fake images) 500 images for training and 500 images for validation

**Note:** FFHQ stands for Flickr-Faces-HQ, a high quality image data set of human faces created originally 
as a benchmark for generative adversarial networks (GAN). (Real Photos) StyleGAN2 on the other hand makes 
use of the different resolution features maps generated in the architecture and uses skip connections to 
connect low-res feature maps to final generated image. (AI-Generated Faces.)

```python
file_path = "./data"
for dirpath, dirnames, filenames in os.walk(file_path):
    N_c = len(filenames)
    print("No. of files in ", dirpath, "is", N_c)

#Training Set
NEG_TRAIN_DIR = "data/train/ffhq"
POS_TRAIN_DIR = "data/train/stylegan2"

#Validation Set
NEG_VAL_DIR = "data/validation/ffhq"
POS_VAL_DIR = "data/validation/stylegan2"
```


## Data Preprocessing
> Note that a colour image is represented digitally in 3 dimensions: Width, Height, and RGB colour 
![](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-41.png)

> A greyscale image is represented with just: Width, Height, and colour
![](https://forum.processing.org/two/uploads/imageupload/023/F3L8WBKSI7XF.png)

Hence, we require some function to preprocess each image into a 1D array of features.


```python
WIDTH = 256
HEIGHT = 256
 
#Features removal to reduce dimension for processing.
def format_data(data_dir, filename):
    infile = data_dir + "/" + filename
    #Documentation of PIL.Image https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#the-image-class
    img = PIL.Image.open(infile)
 
    # Convert to grayscale to speed up processing time
    img = img.convert('L')
 
    # Resize to speed up processing time
    img = img.resize((WIDTH,HEIGHT))
    np_img = np.asarray(img)
 
    # Normalise from pixel values from [0,255] to [0,1], https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0
    np_img = np_img / 255
 
    # We are making it into a 1D array for simplicity
    pixel_count = np.shape(np_img)[0] * np.shape(np_img)[1]
    np_img = np.reshape(np_img, pixel_count)    
 
    return np_img
```

Further Function to perform data preprocessing of all images in training and validation sets.

```python
#label classes
REAL_CLASS = "real"
FAKE_CLASS = "fake"

#assign label to each data
def load_files(pos_train_dir, neg_train_dir, pos_val_dir, neg_val_dir):
    train_data = []
    train_labels = []
    val_data = []
    val_labels = []
    rel_test_data = []

    print('Processing Positive Labels in Training Set')

    for filename in tqdm(os.listdir(pos_train_dir)):
        #preprocessed data
        np_img = format_data(pos_train_dir, filename)
        #load preprocessed
        train_data.append(np_img)
        #load annotations
        train_labels.append(FAKE_CLASS)

    print('Processing Negative Labels in Training Set')

    for filename in tqdm(os.listdir(neg_train_dir)):
        np_img = format_data(neg_train_dir, filename)
        train_data.append(np_img)
        train_labels.append(REAL_CLASS)

    print('Processing Positive Labels in Validation Set')

    for filename in tqdm(sorted(os.listdir(pos_val_dir))):
        np_img = format_data(pos_val_dir, filename)
        val_data.append(np_img)
        val_labels.append(FAKE_CLASS)

    print('Processing Negative Labels in Validation Set')

    for filename in tqdm(sorted(os.listdir(neg_val_dir))):
        np_img = format_data(neg_val_dir, filename)
        val_data.append(np_img)
        val_labels.append(REAL_CLASS)

    return train_data, train_labels, val_data, val_labels
```

After that, we run the load_files function and perform the preprocessing and allocate to respective variables

```python
train_data, train_labels, val_data, val_labels = load_files(POS_TRAIN_DIR, NEG_TRAIN_DIR, POS_VAL_DIR, NEG_VAL_DIR)
```



## Training the Model
scikit-learn is a machine learning library that provides a selection of efficient tools for machine learning and 
statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence 
interface in Python.

Here, we will be using the Logisitic Regression Model

To train the model on the training set:

```python
model = sklearn.linear_model.LogisticRegression(verbose=True, max_iter = 100)
model.fit(train_data, train_labels)
```

## Evaluating the Model Trained
Make predictions on the validation set and Calcuate accuracy of the model 
(number of correct predictions / total number of predictions)
```python
predictions = model.predict(val_data)
accuracy = sklearn.metrics.accuracy_score(val_labels, predictions) * 100
print("Model accuracy = ", accuracy, "%")
```

Next, we may want to visualise the misclassified images to better understand failures.
- Display misclassified fake images - Fake images that are classified as Real
- Display misclassified real images - Real images that are classified as Fake
- Display correctly classified fake images

```python
# Find misclassified images
misclass_fake_images = []
misclass_real_images = []

#get index of wrongly classify images
misclass_index = np.where(predictions != val_labels)

for index in misclass_index[0]:
    if val_labels[index] == FAKE_CLASS:
        #False Negative (Fake predicted as Real)
        misclass_fake_images.append(index)
    else:
        #False Positive (Real predicted as Fake)
        misclass_real_images.append(index)
        
truepos_images = []
truepos_index = np.where(predictions == val_labels)

#True Positive (Correctly classified fake images)
for index in truepos_index[0]:
    if val_labels[index] == FAKE_CLASS:
        #True Negative
        truepos_images.append(index)


print("False Negative Images")
num_to_show = min(10, len(misclass_fake_images))
fig, plot = plt.subplots(1, num_to_show, figsize=(40,4))
for count, index in enumerate(misclass_fake_images[:num_to_show]):
    reshaped = np.reshape(val_data[index], (WIDTH,HEIGHT))
    plot[count].imshow(reshaped, cmap='gray', vmin=0, vmax=1)


print("False Positive Images")
num_to_show = min(10, len(misclass_real_images))
fig, plot = plt.subplots(1, num_to_show, figsize=(40,4))
for count, index in enumerate(misclass_real_images[:num_to_show]):
    reshaped = np.reshape(val_data[index], (WIDTH,HEIGHT))
    plot[count].imshow(reshaped, cmap='gray', vmin=0, vmax=1)

print("True Positive Images")
num_to_show = min(10, len(truepos_images))
fig, plot = plt.subplots(1, num_to_show, figsize=(40,4))
for count, index in enumerate(truepos_images[:num_to_show]):
    reshaped = np.reshape(val_data[index], (WIDTH,HEIGHT))
    plot[count].imshow(reshaped, cmap='gray', vmin=0, vmax=1)

#Try your own directory and image filename
img1_dir = 'data/validation/ffhq'
img1_name = '00509.png'
np_img1 = format_data(img1_dir, img1_name)
#Print prediction
print(model.predict([np_img1]))
display(Image(img1_dir + '/' + img1_name, width = 250, height = 250))

#Try your own directory and image filename
img1_dir = 'data/validation/stylegan2'
img1_name = '000559.png'
np_img1 = format_data(img1_dir, img1_name)
#Print prediction
print(model.predict([np_img1]))
display(Image(img1_dir + '/' + img1_name, width = 250, height = 250))
```





Credit and reference materials from DSTA Hackathon Workshop Organisers (Official Open Materials). 
Adapted to operate locally on PyCharm.